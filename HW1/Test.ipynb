{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias_of_avg_theta_hat: 0.5508242842453827\n",
      "avg_theta_hat: [0.00386105 0.39194461]\n",
      "avg_predictions: [-0.0077926   0.00553988]\n",
      "overall_bias: 0.9153128369886382\n",
      "overall_variance: 0.09497855782623126\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the Tikhonov regularization approach\n",
    "def tikhonov_regularization(x, y, alpha):\n",
    "    A = np.vstack([np.ones_like(x), x]).T\n",
    "    # Gamma = alpha*np.eye(2)  # Regularization matrix\n",
    "    Gamma = np.zeros((2,2))\n",
    "    Gamma[1:,1:] = alpha*np.eye(1)\n",
    "    theta = np.linalg.inv(A.T @ A + Gamma.T @ Gamma) @ A.T @ y\n",
    "    return theta\n",
    "\n",
    "# Generate or load your training datasets\n",
    "def generate_datasets(n_datasets, n_samples):\n",
    "    datasets = []\n",
    "    for _ in range(n_datasets):\n",
    "        x = np.random.uniform(-1, 1, n_samples)\n",
    "        # y = np.sin(np.pi * x) + np.random.normal(0, 0.1, n_samples)  # Add noise to y\n",
    "        y = np.sin(np.pi * x)\n",
    "        datasets.append((x, y))\n",
    "    return datasets\n",
    "\n",
    "# Calculate bias\n",
    "def calc_bias(theta_hat):\n",
    "    x = np.linspace(-1, 1, 1000).reshape(1000,1)\n",
    "    x_tile = np.hstack((np.ones_like(x),x))\n",
    "    bias = np.mean((x_tile @ theta_hat-np.sin(np.pi*x))**2)\n",
    "    return bias\n",
    "\n",
    "# Define the number of datasets and samples per dataset\n",
    "n_datasets = 1000\n",
    "n_samples = 2\n",
    "alpha = 0.5\n",
    "\n",
    "# Generate datasets\n",
    "datasets = generate_datasets(n_datasets, n_samples)\n",
    "\n",
    "# Initialize lists to store coefficients, predictions, biases, and variances\n",
    "theta_hats_list = []\n",
    "predictions_list = []\n",
    "biases_list = []\n",
    "variances_list = []\n",
    "\n",
    "# Train the Tikhonov regularization estimator on each dataset\n",
    "for i, (x, y) in enumerate(datasets):\n",
    "    # 1. Train linear regression model\n",
    "    theta_hat = tikhonov_regularization(x, y, alpha)\n",
    "    theta_hats_list.append(theta_hat)\n",
    "\n",
    "    # 2. Predictions\n",
    "    # Transfer x to x_tile\n",
    "    x_tile = np.vstack((np.ones_like(x),x)).T\n",
    "    Y_predict = x_tile @ theta_hat\n",
    "    predictions_list.append(Y_predict)\n",
    "\n",
    "    # 3. Bias\n",
    "    # bias = np.mean((Y_predict - y)**2)\n",
    "    bias = calc_bias(theta_hat)\n",
    "    biases_list.append(bias)\n",
    "\n",
    "    # 4. Variance\n",
    "    variance = np.var(Y_predict)\n",
    "    variances_list.append(variance)\n",
    "\n",
    "# Calculate average coefficients\n",
    "avg_theta_hat = np.mean(theta_hats_list, axis=0)\n",
    "bias_of_avg_theta_hat = calc_bias(avg_theta_hat)\n",
    "\n",
    "# Calculate average predictions\n",
    "avg_predictions = np.mean(predictions_list, axis=0)\n",
    "\n",
    "# Calculate overall bias and variance\n",
    "overall_bias = np.mean(biases_list)\n",
    "overall_variance = np.mean(variances_list)\n",
    "\n",
    "print(\"bias_of_avg_theta_hat:\", bias_of_avg_theta_hat)\n",
    "print(\"avg_theta_hat:\", avg_theta_hat)\n",
    "print(\"avg_predictions:\", avg_predictions)\n",
    "\n",
    "print(\"overall_bias:\", overall_bias)\n",
    "print(\"overall_variance:\", overall_variance)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario (b) - linear line h(x) = ax+b:\n",
      "Average hypothesis a: -0.0001554852805187565\n",
      "Average hypothesis b: -0.337859085805639\n",
      "Bias: 0.5432711761780847\n",
      "Variance: 0.4066053963440488\n",
      "Risk: 0.9498765725221335\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_bias(avg_hypothesis_a, avg_hypothesis_b):\n",
    "    x = np.random.uniform(-1, 1, 10000)\n",
    "    bias = np.mean((avg_hypothesis_a * x + avg_hypothesis_b - x ** 2) ** 2)\n",
    "    return bias\n",
    "\n",
    "\n",
    "def calc_metrics(hypothesises_a, hypothesises_b, data_x):\n",
    "    avg_hypothesis_a = np.mean(hypothesises_a)\n",
    "    avg_hypothesis_b = np.mean(hypothesises_b)\n",
    "    bias = calc_bias(avg_hypothesis_a, avg_hypothesis_b)\n",
    "    variance = 0.5 * (np.mean(((hypothesises_a * data_x[:, 0] + hypothesises_b) - (\n",
    "                avg_hypothesis_a * data_x[:, 0] + avg_hypothesis_b)) ** 2) + np.mean(\n",
    "        ((hypothesises_a * data_x[:, 1] + hypothesises_b) - (avg_hypothesis_a * data_x[:, 1] + avg_hypothesis_b)) ** 2))\n",
    "    risk = bias + variance\n",
    "    return avg_hypothesis_a, avg_hypothesis_b, bias, variance, risk\n",
    "\n",
    "\n",
    "data_x = np.random.uniform(-1, 1, size=(10000, 2))\n",
    "data_y = np.sin(np.pi * data_x)\n",
    "\n",
    "# hypothesises_a = (data_y[:, 0] - data_y[:, 1]) / (data_x[:, 0] - data_x[:, 1])\n",
    "hypothesises_a = data_x[:, 0] + data_x[:, 1]\n",
    "# hypothesises_b = data_y[:, 0] -hypothesises_a*data_x[:, 0]\n",
    "hypothesises_b = ((data_y[:, 0] + data_y[:, 1]) - hypothesises_a * (data_x[:, 0] + data_x[:, 1])) * 0.5\n",
    "\n",
    "avg_hypothesis_a, avg_hypothesis_b, bias, variance, risk = calc_metrics(hypothesises_a, hypothesises_b, data_x)\n",
    "print(\"Scenario (b) - linear line h(x) = ax+b:\")\n",
    "print(\"Average hypothesis a:\", avg_hypothesis_a)\n",
    "print(\"Average hypothesis b:\", avg_hypothesis_b)\n",
    "print(\"Bias:\", bias)\n",
    "print(\"Variance:\", variance)\n",
    "print(\"Risk:\", risk)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario (a) - Constant line h(x) = b:\n",
      "Average hypothesis: -0.0036300878225968497\n",
      "Bias: 0.19590410234900257\n",
      "Variance: 0.24983767665750384\n",
      "Risk: 0.4457417790065064\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def calc_bias(avg_hypothesis):\n",
    "    x = np.random.uniform(-1, 1, 10000)\n",
    "    bias = np.mean((avg_hypothesis - x ** 2) ** 2)\n",
    "    return bias\n",
    "\n",
    "def calc_metrics(hypothesis):\n",
    "    avg_hypothesis = np.mean(hypothesis)\n",
    "    bias = calc_bias(avg_hypothesis)\n",
    "    variance = np.mean((hypothesis - avg_hypothesis) ** 2)\n",
    "    risk = bias + variance\n",
    "    return avg_hypothesis, bias, variance, risk\n",
    "\n",
    "\n",
    "data_x = np.random.uniform(-1, 1, size=(10000, 2))\n",
    "data_y = np.sin(np.pi * data_x)\n",
    "\n",
    "hypothesises = (data_y[:, 0] + data_y[:, 1]) / 2\n",
    "avg_hypothesis_a, bias_a, variance_a, risk_a = calc_metrics(hypothesises)\n",
    "print(\"Scenario (a) - Constant line h(x) = b:\")\n",
    "print(\"Average hypothesis:\", avg_hypothesis_a)\n",
    "print(\"Bias:\", bias_a)\n",
    "print(\"Variance:\", variance_a)\n",
    "print(\"Risk:\", risk_a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
